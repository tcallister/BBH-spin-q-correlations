{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json,glob\n",
    "from scipy.interpolate import interp2d\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from plot_corner import getBounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# macros_bayes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Model neglecting both correlations and negative spins\n",
    "# Loop across parallel runs and record the final dynesty evidences for each run\n",
    "logz_noEvol_noNeg = np.array([])\n",
    "fs = glob.glob(\"../code/dynesty_output/dynesty_results_noEvol_noNeg_job?.npy\")\n",
    "for f in fs:\n",
    "    logz_noEvol_noNeg = np.append(logz_noEvol_noNeg,np.load(f,allow_pickle=True)[()]['logz'][-1])\n",
    "\n",
    "# Model neglecting correlations\n",
    "logz_noEvol = np.array([])\n",
    "fs = glob.glob(\"../code/dynesty_output/dynesty_results_noEvol_job?.npy\")\n",
    "for f in fs:\n",
    "    logz_noEvol = np.append(logz_noEvol,np.load(f,allow_pickle=True)[()]['logz'][-1])\n",
    "\n",
    "# Model neglecting negative spins\n",
    "logz_evol_noNeg = np.array([])\n",
    "fs = glob.glob(\"../code/dynesty_output/dynesty_results_noNeg_job?.npy\")\n",
    "for f in fs:\n",
    "    logz_evol_noNeg = np.append(logz_evol_noNeg,np.load(f,allow_pickle=True)[()]['logz'][-1])\n",
    "\n",
    "# Model including negative spins and spin-q correlations\n",
    "logz_evol = np.array([])\n",
    "fs = glob.glob(\"../code/dynesty_output/dynesty_results_job?.npy\")\n",
    "for f in fs:\n",
    "    logz_evol = np.append(logz_evol,np.load(f,allow_pickle=True)[()]['logz'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Helper function to compute both the mean and std deviation of the log-Bayes between two hypotheses\n",
    "def getBayes(logzs_A,logzs_B):\n",
    "    bayes = logzs_A-np.mean(logzs_B)\n",
    "    return np.mean(bayes), np.std(bayes)\n",
    "\n",
    "with open('macros_bayes.txt','w') as macrofile:\n",
    "    \n",
    "    mean,std = getBayes(logz_noEvol_noNeg,logz_noEvol_noNeg)\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\evidenceNoEvolNoNeg}}{{{0:.2f}}}\".format(mean))\n",
    "    macrofile.write(\"\\n\")\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\evidenceNoEvolNoNegError}}{{{0:.2f}}}\".format(std))\n",
    "    macrofile.write(\"\\n\")\n",
    "    \n",
    "    mean,std = getBayes(logz_noEvol,logz_noEvol_noNeg)\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\evidenceNoEvolYesNeg}}{{{0:.2f}}}\".format(mean))\n",
    "    macrofile.write(\"\\n\")\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\evidenceNoEvolYesNegError}}{{{0:.2f}}}\".format(std))\n",
    "    macrofile.write(\"\\n\")\n",
    "    \n",
    "    mean,std = getBayes(logz_evol_noNeg,logz_noEvol_noNeg)\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\evidenceYesEvolNoNeg}}{{{0:.2f}}}\".format(mean))\n",
    "    macrofile.write(\"\\n\")\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\evidenceYesEvolNoNegError}}{{{0:.2f}}}\".format(std))\n",
    "    macrofile.write(\"\\n\")\n",
    "    \n",
    "    mean,std = getBayes(logz_evol,logz_noEvol_noNeg)\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\evidenceYesEvolYesNeg}}{{{0:.2f}}}\".format(mean))\n",
    "    macrofile.write(\"\\n\")\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\evidenceYesEvolYesNegError}}{{{0:.2f}}}\".format(std))\n",
    "    macrofile.write(\"\\n\")\n",
    "    \n",
    "    mean,std = getBayes(logz_evol,logz_evol_noNeg)\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\bayesNegWhenCorrelated}}{{{0:.2f}}}\".format(mean))\n",
    "    macrofile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# macros_pe_evol.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Record median and 90% credible uncertainties for parameters of the spin vs. q model\n",
    "samps = np.load('./../code/output/processed_emcee_samples_plPeak_r00.npy')\n",
    "with open('macros_pe_evol.txt','w') as macrofile:\n",
    "    \n",
    "    macrofile.write(\"\\\\newcommand{{\\\\evolMean}}{{{0:.2f}^{{+{1:.2f}}}_{{-{2:.2f}}}}}\".format(*getBounds(samps[:,7])))\n",
    "    macrofile.write(\"\\n\")\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\evolSigma}}{{{0:.2f}^{{+{1:.2f}}}_{{-{2:.2f}}}}}\".format(*getBounds(10.**samps[:,8])))                \n",
    "    macrofile.write(\"\\n\")\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\evolAlpha}}{{{0:.2f}^{{+{1:.2f}}}_{{-{2:.2f}}}}}\".format(*getBounds(samps[:,9])))                \n",
    "    macrofile.write(\"\\n\")\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\evolBeta}}{{{0:.2f}^{{+{1:.2f}}}_{{-{2:.2f}}}}}\".format(*getBounds(samps[:,10])))                \n",
    "    macrofile.write(\"\\n\")\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\evolBetaq}}{{{0:.1f}^{{+{1:.1f}}}_{{-{2:.1f}}}}}\".format(*getBounds(samps[:,5])))                \n",
    "    macrofile.write(\"\\n\")\n",
    "    \n",
    "    # Percentage of samples with negative alpha\n",
    "    alphas = samps[:,9]\n",
    "    percentNegative = (100.*np.where(alphas<0)[0].size/alphas.size)\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\percentAlphaNegative}}{{{0:.1f}\\\\%}}\".format(percentNegative)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# macros_pe_evol_altEvents.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Record information about alpha and beta parameters when re-running with different sets of events\n",
    "\n",
    "samps_no190412 = np.load('./../code/output/processed_emcee_samples_plPeak_no190412_r00.npy')\n",
    "samps_no190517 = np.load('./../code/output/processed_emcee_samples_plPeak_no190517_r00.npy')\n",
    "samps_no190412_no190517 = np.load('./../code/output/processed_emcee_samples_plPeak_no190412_no190517_r00.npy')\n",
    "samps_w190814 = np.load('./../code/output/processed_emcee_samples_plPeak_w190814_r00.npy')\n",
    "\n",
    "with open('macros_pe_evol_altEvents.txt','w') as macrofile:\n",
    "    \n",
    "    # Neglecting GW190517\n",
    "    alphas = samps_no190517[:,9]\n",
    "    percent_negative = 100.*alphas[alphas<0].size/alphas.size\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\percentAlphaNegativeNoOhFiveSeventeen}}{{{0:.1f}\\\\%}}\".format(percent_negative)) \n",
    "    macrofile.write('\\n')\n",
    "    \n",
    "    # Neglecting GW190412\n",
    "    alphas = samps_no190412[:,9]\n",
    "    percent_negative = 100.*alphas[alphas<0].size/alphas.size\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\percentAlphaNegativeNoOhFourTwelve}}{{{0:.1f}\\\\%}}\".format(percent_negative)) \n",
    "    macrofile.write('\\n')\n",
    "    \n",
    "    # Neglecting GW190517 and GW190412\n",
    "    alphas = samps_no190412_no190517[:,9]\n",
    "    percent_negative = 100.*alphas[alphas<0].size/alphas.size\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\percentAlphaNegativeNoOhFourTwelveOrOhFiveSeventeen}}{{{0:.1f}\\\\%}}\".format(percent_negative)) \n",
    "    macrofile.write('\\n')\n",
    "    \n",
    "    # Including GW190814\n",
    "    alphas = samps_w190814[:,9]\n",
    "    betas = samps_w190814[:,10]\n",
    "    percent_negative = 100.*alphas[alphas<0].size/alphas.size\n",
    "    percent_negative_betas = 100.*betas[betas<0].size/betas.size\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\percentAlphaNegativeWithOhEightFourteen}}{{{0:.1f}\\\\%}}\".format(percent_negative)) \n",
    "    macrofile.write('\\n')\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\percentBetaNegativeWithOhEightFourteen}}{{{0:.1f}\\\\%}}\".format(percent_negative_betas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# macros_pe_noEvol.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Parameter estimates when excluding the possibility of spin-q correlations\n",
    "samps_no_evol = np.load('../code/output/processed_emcee_samples_plPeak_noEvol_r00.npy')\n",
    "with open('macros_pe_noEvol.txt','w') as macrofile:\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\noEvolMean}}{{{0:.2f}^{{+{1:.2f}}}_{{-{2:.2f}}}}}\".format(*getBounds(samps_no_evol[:,7])))\n",
    "    macrofile.write(\"\\n\")\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\noEvolSigma}}{{{0:.2f}^{{+{1:.2f}}}_{{-{2:.2f}}}}}\".format(*getBounds(10.**samps_no_evol[:,8])))                \n",
    "    macrofile.write(\"\\n\")\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\noEvolBetaq}}{{{0:.1f}^{{+{1:.1f}}}_{{-{2:.1f}}}}}\".format(*getBounds(samps_no_evol[:,5])))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# macros_pe_inj.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Information about results of mock injection study\n",
    "injection_samps_plPeak = np.load('../injection-study/processed_emcee_samples_injection_plPeak_r02.npy')\n",
    "alphas_inj = injection_samps_plPeak[:,-2]\n",
    "betas_inj = injection_samps_plPeak[:,-1]\n",
    "\n",
    "# We want to compute the probability contour along which lies the point (alpha,beta) = (0,0)\n",
    "# First, take a 2D histogram of our samples and smooth slightly with a gaussian kernel\n",
    "xgrid = np.linspace(-1.5,1,100)\n",
    "ygrid = np.linspace(-2,1.5,99)\n",
    "dx = xgrid[1]-xgrid[0]\n",
    "dy = ygrid[1]-ygrid[0]\n",
    "heights,edgex,edgey = np.histogram2d(alphas_inj,betas_inj,bins=(xgrid,ygrid))\n",
    "heights = gaussian_filter(heights,2.5)\n",
    "heights /= np.sum(heights)*dx*dy\n",
    "\n",
    "# Use resulting heights to build an interpolant for the 2D probability distribution p(alpha,beta)\n",
    "# and evaluate at origin\n",
    "interpolator = interp2d((xgrid[1:] + xgrid[:-1])/2,(ygrid[1:] + ygrid[:-1])/2,heights.T)\n",
    "height_at_origin = interpolator(0,0)[0]\n",
    "\n",
    "# Next, calculate cumulative probability as a function of probability density,\n",
    "# integrating outwards from the max-probability point in the (alpha,beta) plane\n",
    "heights_large_to_small = np.sort(heights.reshape(-1))[::-1]\n",
    "cdf = np.cumsum(heights_large_to_small)*dx*dy\n",
    "\n",
    "# Get integrated probability inside the contour intersecting (alpha,beta) = (0,0)\n",
    "percentile_at_origin = 100.*np.interp(height_at_origin,heights_large_to_small[::-1],cdf[::-1])\n",
    "\n",
    "# Write macro file\n",
    "with open('macros_pe_inj.txt','w') as macrofile:\n",
    "    \n",
    "    macrofile.write(\"\\\\newcommand{{\\\\injMean}}{{{0:.2f}^{{+{1:.2f}}}_{{-{2:.2f}}}}}\".format(*getBounds(injection_samps_plPeak[:,7])))\n",
    "    macrofile.write(\"\\n\")\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\injSigma}}{{{0:.2f}^{{+{1:.2f}}}_{{-{2:.2f}}}}}\".format(*getBounds(10.**injection_samps_plPeak[:,8])))                \n",
    "    macrofile.write(\"\\n\")\n",
    "    macrofile.write(\"\\\\newcommand{{\\\\injQuantileAtOrigin}}{{{0:.0f}}}\".format(percentile_at_origin))                \n",
    "    macrofile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# macros_ppc.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "reweightedDict = np.load('reweighted_samples_noEvolution.npy',allow_pickle=True)[()]\n",
    "mock_q_noEvol = reweightedDict['mock_q']\n",
    "mock_x_noEvol = reweightedDict['mock_chi']\n",
    "resampled_q_noEvol = reweightedDict['resampled_q']\n",
    "resampled_x_noEvol = reweightedDict['resampled_chi']\n",
    "\n",
    "# Next, repeatedly draw catalogs of mock events and reweighted posteriors, computing the least-squares slope for each\n",
    "# Instantiate arrays to hold results\n",
    "n_catalogs = resampled_x_noEvol.shape[1]\n",
    "obs_slope = np.zeros(n_catalogs)\n",
    "mock_slope = np.zeros(n_catalogs)\n",
    "\n",
    "# Loop over catalog instantiations\n",
    "for i in range(n_catalogs):\n",
    "    \n",
    "    # Read out spins and mass ratios\n",
    "    obs_qs = resampled_q_noEvol[:,i]\n",
    "    mock_qs = mock_q_noEvol[:,i]\n",
    "    obs_xs = resampled_x_noEvol[:,i]\n",
    "    mock_xs = mock_x_noEvol[:,i]\n",
    "    \n",
    "    # Compute slopes and save\n",
    "    X = np.transpose([np.ones(obs_qs.size),obs_qs])\n",
    "    b,m = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(obs_xs)\n",
    "    obs_slope[i] = m\n",
    "    \n",
    "    X = np.transpose([np.ones(mock_qs.size),mock_qs])\n",
    "    b,m = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(mock_xs)\n",
    "    mock_slope[i] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "reweightedDict_evol = np.load('reweighted_samples_yesEvolution.npy',allow_pickle=True)[()]\n",
    "resampled_q_evol = reweightedDict_evol['resampled_q']\n",
    "resampled_x_evol = reweightedDict_evol['resampled_chi']\n",
    "mock_q_evol = reweightedDict_evol['mock_q']\n",
    "mock_x_evol = reweightedDict_evol['mock_chi']\n",
    "\n",
    "n_catalogs = resampled_q_evol.shape[1]\n",
    "obs_slope_evol = np.zeros(n_catalogs)\n",
    "mock_slope_evol = np.zeros(n_catalogs)\n",
    "\n",
    "for i in range(n_catalogs):\n",
    "    \n",
    "    obs_qs = resampled_q_evol[:,i]\n",
    "    mock_qs = mock_q_evol[:,i]\n",
    "    obs_xs = resampled_x_evol[:,i]\n",
    "    mock_xs = mock_x_evol[:,i]\n",
    "    \n",
    "    X = np.transpose([np.ones(obs_qs.size),obs_qs])\n",
    "    b,m = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(obs_xs)\n",
    "    obs_slope_evol[i] = m\n",
    "    \n",
    "    X = np.transpose([np.ones(mock_qs.size),mock_qs])\n",
    "    b,m = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(mock_xs)\n",
    "    mock_slope_evol[i] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with open('macros_ppc.txt','w') as macrofile:\n",
    "    \n",
    "    percentage = int(100.*(np.where(obs_slope<mock_slope)[0].size/n_catalogs))\n",
    "    macrofile.write('\\\\newcommand{{\\\\FracBelow}}{{{0}\\\\%}}'.format(percentage))\n",
    "    macrofile.write('\\n')\n",
    "    \n",
    "    mean = np.mean(obs_slope)\n",
    "    macrofile.write('\\\\newcommand{{\\\\meanObsSlopeBase}}{{{0:.1f}}}'.format(mean))\n",
    "    macrofile.write('\\n')\n",
    "    \n",
    "    mean_evol = np.mean(obs_slope_evol)\n",
    "    mean_evol_predicted = np.mean(mock_slope_evol)\n",
    "    macrofile.write('\\\\newcommand{{\\\\meanObsSlopeEvol}}{{{0:.2f}}}'.format(mean_evol))\n",
    "    macrofile.write('\\n')\n",
    "    macrofile.write('\\\\newcommand{{\\\\meanMockSlopeEvol}}{{{0:.2f}}}'.format(mean_evol_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igwn-py37",
   "language": "python",
   "name": "igwn-py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
